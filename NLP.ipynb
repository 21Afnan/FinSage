{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d61ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "# speech_recognition is a library we use \n",
    "# for taking an real time input from the user in voice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9b5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Recognizer is a class from sr package whose object \n",
    "is created to call its ftc \n",
    "listens to take voice input form the user\"\"\"\n",
    "recognizer=sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbd911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening!!......Please speak now?\n"
     ]
    }
   ],
   "source": [
    "\"\"\" with is used when we are opening any wav file or any text file \n",
    "like excel which closses automaticaly aftr its use and opens auto when required\n",
    "as microphone is a class used to take audio as it is a source and \n",
    "listen is a function of recognizer class so both are imp \n",
    " which records audio and it takes just 60seconds \n",
    "audio not more then that\"\"\"\n",
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "      print(\"Listening!!......Please speak now?\")\n",
    "      audio=recognizer.listen(source,timeout=5,phrase_time_limit=20)\n",
    "except sr.WaitTimeoutError:\n",
    "    print(\"No speech detected â€” you stayed silent too long.\")\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Could not understand the audio (maybe distortion or unclear speech).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Some other error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe80a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.wav\", \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3797f82a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\speech_recognition\\recognizers\\google.py:262\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[0;32m    255\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[0;32m    256\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[0;32m    257\u001b[0m )\n\u001b[0;32m    259\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[0;32m    260\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[0;32m    261\u001b[0m )\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_parser\u001b[38;5;241m.\u001b[39mparse(response_text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\speech_recognition\\recognizers\\google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[1;34m(self, response_text)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_result(response_text)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\speech_recognition\\recognizers\\google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[1;34m(response_text)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = recognizer.recognize_google(audio)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98637c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper=WhisperModel(\"tiny\",compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d68a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "whisper.transcribe(\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccdf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6da6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
